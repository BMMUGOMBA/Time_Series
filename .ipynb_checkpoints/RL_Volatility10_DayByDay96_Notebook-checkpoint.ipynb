{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "448fe965",
   "metadata": {},
   "source": [
    "\n",
    "# RL Agent for **Volatility 10 Index** (DayByDay96) — Research Notebook\n",
    "\n",
    "This notebook is tailored to your dataset: **`DayByDay96_Volatility 10 Index.csv`** where each row contains **96 past timestamps** of prices (close values), representing a sliding window.  \n",
    "We build a **row-wise RL environment**: each environment step moves from row *t* → row *t+1*, where the **observation** is the full 96-length window at *t*, and the **reward** is the PnL from the change in the **last price** of row *t* to the last price of row *t+1*, minus costs (spread/commission/slippage).\n",
    "\n",
    "> ⚠️ Research/education only. Markets (and synthetic indices) are non-stationary. Use strict out-of-sample evaluation and realistic costs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfc7808",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If needed (local environment), uncomment:\n",
    "# !pip install numpy pandas matplotlib gymnasium stable-baselines3 torch --quiet\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "# Optional: Stable-Baselines3 (works if installed)\n",
    "try:\n",
    "    from stable_baselines3 import PPO\n",
    "    from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "    from stable_baselines3.common.callbacks import EvalCallback\n",
    "    SB3_AVAILABLE = True\n",
    "except Exception as e:\n",
    "    SB3_AVAILABLE = False\n",
    "    print(\"Stable-Baselines3 not available. You can still use the custom env and baselines.\\n\", e)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10,4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253ba481",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_PATH = Path(\"/mnt/data/DayByDay96_Volatility 10 Index.csv\")  # Adjust if running elsewhere\n",
    "\n",
    "# The file has no header — 96 columns of numeric prices per row.\n",
    "df96 = pd.read_csv(DATA_PATH, header=None).apply(pd.to_numeric, errors='coerce')\n",
    "assert df96.shape[1] == 96, f\"Expected 96 columns per row, got {df96.shape[1]}\"\n",
    "df96 = df96.dropna().reset_index(drop=True)\n",
    "\n",
    "print(\"Shape (rows, 96):\", df96.shape)\n",
    "df96.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7eb54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Strategy: take the **last column** of each 96-length row as the \"current close\".\n",
    "# This gives a continuous series if rows are ordered chronologically.\n",
    "close_series = df96.iloc[:, -1].values.astype(float)\n",
    "\n",
    "# Quick sanity checks & plot\n",
    "print(\"Continuous series length:\", len(close_series))\n",
    "plt.plot(close_series)\n",
    "plt.title(\"Volatility 10 Index — Continuous Close Series (from last column of each row)\")\n",
    "plt.xlabel(\"Step (row index)\"); plt.ylabel(\"Close\"); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7fcce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _rsi(x, n=14):\n",
    "    x = np.asarray(x, dtype=np.float64)\n",
    "    diff = np.diff(x, prepend=x[0])\n",
    "    gain = np.where(diff > 0, diff, 0.0)\n",
    "    loss = np.where(diff < 0, -diff, 0.0)\n",
    "    # Wilder's smoothing (approx via rolling mean here for simplicity)\n",
    "    avg_gain = pd.Series(gain).rolling(n).mean().bfill().values\n",
    "    avg_loss = pd.Series(loss).rolling(n).mean().bfill().values\n",
    "    rs = np.divide(avg_gain, np.maximum(avg_loss, 1e-12))\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi\n",
    "\n",
    "def _ema(x, n):\n",
    "    alpha = 2/(n+1)\n",
    "    y = np.empty_like(x, dtype=np.float64)\n",
    "    y[0] = x[0]\n",
    "    for i in range(1, len(x)):\n",
    "        y[i] = alpha*x[i] + (1-alpha)*y[i-1]\n",
    "    return y\n",
    "\n",
    "def build_row_features(win):\n",
    "    \"\"\"win: shape (96,) — return compact features per window\n",
    "    Features:\n",
    "      - normalized log-returns (z-scored)\n",
    "      - EMA(10)-EMA(50) over the window (last value)\n",
    "      - RSI(14) (last value, scaled to [0,1])\n",
    "      - rolling volatility of returns (last value)\n",
    "    \"\"\"\n",
    "    w = np.asarray(win, dtype=np.float64)\n",
    "    rets = np.diff(np.log(w + 1e-12), prepend=np.log(w[0]+1e-12))\n",
    "    # Normalize window returns to be roughly stationary for the policy net\n",
    "    mu, sd = rets.mean(), rets.std() + 1e-12\n",
    "    rets_z = (rets - mu) / sd\n",
    "\n",
    "    ema10 = _ema(w, 10)\n",
    "    ema50 = _ema(w, 50)\n",
    "    rsi14 = _rsi(w, 14) / 100.0\n",
    "    vol20 = pd.Series(rets).rolling(20).std().bfill().values\n",
    "\n",
    "    # Compact representation: stack 96 rets_z + 3 scalars (use last values)\n",
    "    feat = np.concatenate([rets_z, [\n",
    "        (ema10[-1] - ema50[-1]) / (sd * 10),  # scale diff to comparable magnitude\n",
    "        rsi14[-1],\n",
    "        vol20[-1]\n",
    "    ]])\n",
    "    return feat.astype(np.float32)\n",
    "\n",
    "# Build feature matrix for all rows (except the very first if needed)\n",
    "features = np.vstack([build_row_features(row) for _, row in df96.iterrows()])\n",
    "features.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14b60a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DayByDay96Env(gym.Env):\n",
    "    \"\"\"Row-wise environment for 96-length windows.\n",
    "    Observation: features derived from the 96-length price window at row t.\n",
    "    Action: 0=flat, 1=long, 2=short\n",
    "    Reward: change in last-close from row t to t+1, * position, minus costs.\n",
    "    Costs use 'points' (index points) rather than FX pips.\n",
    "    \"\"\"\n",
    "    metadata = {\"render_modes\": [\"human\"]}\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        windows: np.ndarray,          # shape (N, 96) raw price windows\n",
    "        costs: dict | None = None,    # dict with 'spread_points', 'commission', 'slippage_points', 'flip_penalty'\n",
    "        feature_builder=build_row_features\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.windows = windows.astype(np.float64)\n",
    "        self.N = self.windows.shape[0]\n",
    "        self.feature_builder = feature_builder\n",
    "\n",
    "        self.costs = {\n",
    "            \"spread_points\": 0.5,     # tweak based on your broker/synthetic index conditions\n",
    "            \"commission\": 0.0,\n",
    "            \"slippage_points\": 0.0,\n",
    "            \"flip_penalty\": 0.0\n",
    "        }\n",
    "        if costs:\n",
    "            self.costs.update(costs)\n",
    "\n",
    "        # Precompute features for speed\n",
    "        self.features = np.vstack([self.feature_builder(w) for w in self.windows])\n",
    "        obs_dim = self.features.shape[1]\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(obs_dim,), dtype=np.float32)\n",
    "        self.action_space = spaces.Discrete(3)\n",
    "\n",
    "        self._reset_state()\n",
    "\n",
    "    def _reset_state(self):\n",
    "        self.t = 0\n",
    "        self.pos = 0   # -1 short, 0 flat, +1 long\n",
    "        self.prev_action = 0\n",
    "        self.equity = 0.0\n",
    "        self.done = False\n",
    "\n",
    "    def reset(self, *, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self._reset_state()\n",
    "        return self._get_obs(), {}\n",
    "\n",
    "    def _get_obs(self):\n",
    "        return self.features[self.t]\n",
    "\n",
    "    def step(self, action: int):\n",
    "        assert self.action_space.contains(action)\n",
    "        if self.t >= self.N - 1:\n",
    "            # No next row to compute reward from\n",
    "            return self._get_obs(), 0.0, True, False, {\"equity\": self.equity}\n",
    "\n",
    "        target_pos = {0:0, 1:+1, 2:-1}[action]\n",
    "        old_pos = self.pos\n",
    "        last_close_t   = self.windows[self.t, -1]\n",
    "        last_close_t1  = self.windows[self.t+1, -1]\n",
    "\n",
    "        # Price change (points)\n",
    "        dP = last_close_t1 - last_close_t\n",
    "\n",
    "        # Trade costs (charged on flips/entries)\n",
    "        trade_cost = 0.0\n",
    "        if target_pos != old_pos:\n",
    "            trade_cost += self.costs[\"commission\"]\n",
    "            trade_cost += self.costs[\"spread_points\"]\n",
    "        # Optional flip penalty\n",
    "        flip_pen = self.costs[\"flip_penalty\"] if (action != self.prev_action) else 0.0\n",
    "\n",
    "        pnl = dP * old_pos\n",
    "        reward = pnl - trade_cost - flip_pen\n",
    "        self.equity += reward\n",
    "\n",
    "        # Move to next row & update state\n",
    "        self.pos = target_pos\n",
    "        self.prev_action = action\n",
    "        self.t += 1\n",
    "        terminated = (self.t >= self.N - 1)\n",
    "\n",
    "        info = {\"equity\": self.equity, \"pnl\": pnl, \"trade_cost\": trade_cost}\n",
    "        return self._get_obs(), float(reward), terminated, False, info\n",
    "\n",
    "    def render(self):\n",
    "        print(f\"t={self.t} pos={self.pos} equity={self.equity:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37374f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N = len(df96)\n",
    "train_end = int(N*0.7)\n",
    "val_end   = int(N*0.85)\n",
    "\n",
    "df_train = df96.iloc[:train_end].values\n",
    "df_val   = df96.iloc[train_end:val_end].values\n",
    "df_test  = df96.iloc[val_end:].values\n",
    "\n",
    "print(\"Splits: \", df_train.shape, df_val.shape, df_test.shape)\n",
    "\n",
    "train_env = DayByDay96Env(df_train, costs={\n",
    "    \"spread_points\": 0.5,     # tune these realistically\n",
    "    \"commission\": 0.0,\n",
    "    \"slippage_points\": 0.0,\n",
    "    \"flip_penalty\": 0.05\n",
    "})\n",
    "val_env = DayByDay96Env(df_val)\n",
    "test_env = DayByDay96Env(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcd1f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ema_baseline_equity(windows, fast=10, slow=50, cost_points=0.5):\n",
    "    # Signal from EMA crossover on each 96-win (using last EMA values)\n",
    "    equity = []\n",
    "    pos = 0\n",
    "    eq = 0.0\n",
    "    prev_signal = 0\n",
    "\n",
    "    for i in range(len(windows)-1):\n",
    "        w = windows[i]\n",
    "        e1, e2 = _ema(w, fast), _ema(w, slow)\n",
    "        signal = 1 if e1[-1] > e2[-1] else -1\n",
    "\n",
    "        dP = windows[i+1, -1] - windows[i, -1]\n",
    "        pnl = dP * pos\n",
    "\n",
    "        # cost on flips\n",
    "        cost = cost_points if (signal != prev_signal) else 0.0\n",
    "        eq += pnl - cost\n",
    "        equity.append(eq)\n",
    "\n",
    "        pos = signal\n",
    "        prev_signal = signal\n",
    "\n",
    "    return np.array(equity)\n",
    "\n",
    "eq_base = ema_baseline_equity(df_test, fast=10, slow=50, cost_points=0.5)\n",
    "plt.plot(eq_base)\n",
    "plt.title(\"EMA(10/50) Baseline Equity (Test)\"); plt.xlabel(\"Step\"); plt.ylabel(\"Equity\"); plt.show()\n",
    "print(\"Baseline final equity:\", float(eq_base[-1]) if len(eq_base) else 0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb84c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if SB3_AVAILABLE:\n",
    "    train_vec = DummyVecEnv([lambda: DayByDay96Env(df_train)])\n",
    "    val_vec   = DummyVecEnv([lambda: DayByDay96Env(df_val)])\n",
    "    model = PPO(\n",
    "        \"MlpPolicy\",\n",
    "        train_vec,\n",
    "        verbose=1,\n",
    "        n_steps=1024,\n",
    "        batch_size=256,\n",
    "        gae_lambda=0.95,\n",
    "        gamma=0.99,\n",
    "        learning_rate=3e-4,\n",
    "        ent_coef=0.0,\n",
    "        clip_range=0.2,\n",
    "        tensorboard_log=\"./ppo_v10_tb/\"\n",
    "    )\n",
    "    eval_cb = EvalCallback(val_vec, best_model_save_path=\"./ppo_v10_best\", log_path=\"./ppo_v10_eval\", eval_freq=5000)\n",
    "    model.learn(total_timesteps=200_000, callback=eval_cb)\n",
    "\n",
    "    # Evaluate on test\n",
    "    best_model = PPO.load(\"./ppo_v10_best/best_model\")\n",
    "    obs, _ = test_env.reset()\n",
    "    done = False\n",
    "    equity_curve = []\n",
    "    actions = []\n",
    "    while not done:\n",
    "        action, _ = best_model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, truncated, info = test_env.step(int(action))\n",
    "        equity_curve.append(info[\"equity\"])\n",
    "        actions.append(int(action))\n",
    "\n",
    "    equity_curve = np.array(equity_curve)\n",
    "    plt.plot(equity_curve)\n",
    "    plt.title(\"PPO Equity Curve (Test)\")\n",
    "    plt.xlabel(\"Step\"); plt.ylabel(\"Equity\"); plt.show()\n",
    "\n",
    "    # Simple metrics\n",
    "    ret = np.diff(np.insert(equity_curve, 0, 0.0))\n",
    "    sharpe = (ret.mean() / (ret.std() + 1e-12)) * np.sqrt(252*24)  # interpret each row as ~hourly if desired\n",
    "    dd = np.maximum.accumulate(equity_curve) - equity_curve\n",
    "    max_dd = dd.max() if len(dd) else 0.0\n",
    "    calmar = (equity_curve[-1] / (abs(max_dd) + 1e-12)) if max_dd > 1e-12 else np.inf\n",
    "\n",
    "    print(f\"Final equity: {equity_curve[-1]:.4f}\")\n",
    "    print(f\"Sharpe (approx): {sharpe:.2f} | MaxDD: {max_dd:.4f} | Calmar: {calmar:.2f}\")\n",
    "else:\n",
    "    print(\"Skip PPO section: install stable-baselines3 to train the RL agent.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48a3f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def walk_forward_indices(N, train_size=0.6, val_size=0.2, step=500):\n",
    "    \"\"\"Yield (train_slice, val_slice, test_slice) index tuples for walk-forward.\n",
    "\n",
    "    step controls how far we roll forward each iteration.\n",
    "\n",
    "    Example: for N=3000, train=1800, val=600, test=600 -> windows rolled by 'step'.\n",
    "\n",
    "    \"\"\"\n",
    "    tr = int(N*train_size); va = int(N*val_size); te = N - tr - va\n",
    "    start = 0\n",
    "    while start + tr + va + te <= N:\n",
    "        yield (slice(start, start+tr),\n",
    "               slice(start+tr, start+tr+va),\n",
    "               slice(start+tr+va, start+tr+va+te))\n",
    "        start += step\n",
    "\n",
    "# Example use (no training here, just showing how you'd iterate):\n",
    "for (tr, va, te) in walk_forward_indices(len(df96), train_size=0.7, val_size=0.15, step=300):\n",
    "    print(\"WF window:\", tr, va, te)\n",
    "    # env_tr = DayByDay96Env(df96.values[tr])\n",
    "    # env_va = DayByDay96Env(df96.values[va])\n",
    "    # Train PPO on env_tr, select on env_va, then evaluate on DayByDay96Env(df96.values[te])\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f895194f",
   "metadata": {},
   "source": [
    "\n",
    "## Notes & Next Steps\n",
    "\n",
    "- **Costs**: Tune `spread_points`, `slippage_points`, and `commission` in `DayByDay96Env` to match realistic conditions for Volatility 10 Index.\n",
    "- **Features**: The `build_row_features` function now uses only the 96-window. You can append your domain features (BTMM/SMC/Wyckoff tags) if you have them per row.\n",
    "- **Actions**: Currently discrete (flat/long/short). For sizing (continuous in [-1,+1]) use SAC/TD3 and map action → exposure.\n",
    "- **Walk-forward**: Use the template to perform rolling re-trains and strict out-of-sample testing on each segment.\n",
    "- **Live/Paper**: If you bridge to MT5/Deriv API, *paper trade first*. Never go live off backtests alone.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
